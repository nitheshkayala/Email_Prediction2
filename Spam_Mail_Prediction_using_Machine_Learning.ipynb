{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqB21QOgMg-G"
   },
   "source": [
    "Importing the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rALI06-oHusw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyKe9o2ONeFv"
   },
   "source": [
    "Data Collection & Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CpStHH8KNcYB"
   },
   "outputs": [],
   "source": [
    "# loading the data from csv file to a pandas Dataframe\n",
    "raw_mail_data = pd.read_csv('mail_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvdMTHmpiYiE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdn-7VE2NxsZ",
    "outputId": "28c19d96-23a2-43c0-86ad-5c1aee7f1b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Category                                            Message\n",
      "0         ham  Go until jurong point, crazy.. Available only ...\n",
      "1         ham                      Ok lar... Joking wif u oni...\n",
      "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         ham  U dun say so early hor... U c already then say...\n",
      "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...       ...                                                ...\n",
      "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568      ham               Will √º b going to esplanade fr home?\n",
      "5569      ham  Pity, * was in mood for that. So...any other s...\n",
      "5570      ham  The guy did some bitching but I acted like i'd...\n",
      "5571      ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(raw_mail_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yhakjIE1N011"
   },
   "outputs": [],
   "source": [
    "# replace the null values with a null string\n",
    "mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)),'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "SJey6H-SOWeK",
    "outputId": "af1b0dfd-2ff9-4af9-cfcd-d0c177dd6ab9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the first 5 rows of the dataframe\n",
    "mail_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IbK82N2gOdar",
    "outputId": "4d1840a1-22b5-468f-d4d0-a4528ef4313c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of rows and columns in the dataframe\n",
    "mail_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhR4U3ATPBdk"
   },
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9EW7QSgeOt4p"
   },
   "outputs": [],
   "source": [
    "# label spam mail as 0;  ham mail as 1;\n",
    "\n",
    "mail_data.loc[mail_data['Category'] == 'spam', 'Category',] = 0\n",
    "mail_data.loc[mail_data['Category'] == 'ham', 'Category',] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxZK1fWwPwII"
   },
   "source": [
    "spam  -  0\n",
    "\n",
    "ham  -  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "t8Rt-FaNPtPE"
   },
   "outputs": [],
   "source": [
    "# separating the data as texts and label\n",
    "\n",
    "X = mail_data['Message']\n",
    "\n",
    "Y = mail_data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QnQeUBGtQPP7",
    "outputId": "a2640f4b-2a1d-4742-9742-3ecbb6017668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Go until jurong point, crazy.. Available only ...\n",
      "1                           Ok lar... Joking wif u oni...\n",
      "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3       U dun say so early hor... U c already then say...\n",
      "4       Nah I don't think he goes to usf, he lives aro...\n",
      "                              ...                        \n",
      "5567    This is the 2nd time we have tried 2 contact u...\n",
      "5568                 Will √º b going to esplanade fr home?\n",
      "5569    Pity, * was in mood for that. So...any other s...\n",
      "5570    The guy did some bitching but I acted like i'd...\n",
      "5571                           Rofl. Its true to its name\n",
      "Name: Message, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cuWDNy5KQQjY",
    "outputId": "1a0a109b-d63a-4cf0-fe4e-b486f1d3d623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       0\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "5567    0\n",
      "5568    1\n",
      "5569    1\n",
      "5570    1\n",
      "5571    1\n",
      "Name: Category, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvHyqdH8QZPH"
   },
   "source": [
    "Splitting the data into training data & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RO2GmbSNQSQH"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tS2c7A4NRa46",
    "outputId": "5d44247f-65d0-457d-8a94-0fd8b45a3b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "(4457,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYQpiACGSBYM"
   },
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nLs847nSRibm"
   },
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'lowercase' parameter of TfidfVectorizer must be an instance of 'bool', an instance of 'numpy.bool_' or an instance of 'int'. Got 'True' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# transform the text data to feature vectors that can be used as input to the Logistic regression\u001b[39;00m\n\u001b[0;32m      3\u001b[0m feature_extraction \u001b[38;5;241m=\u001b[39m TfidfVectorizer(min_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m, lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m X_train_features \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extraction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m X_test_features \u001b[38;5;241m=\u001b[39m feature_extraction\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# convert Y_train and Y_test values as integers\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2131\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2126\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2127\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2128\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2129\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2130\u001b[0m )\n\u001b[1;32m-> 2131\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2133\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2134\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1368\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_documents, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1365\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterable over raw text documents expected, string object received.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[1;32m-> 1368\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_ngram_range()\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_for_unused_params()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 581\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:97\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m constraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m     )\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'lowercase' parameter of TfidfVectorizer must be an instance of 'bool', an instance of 'numpy.bool_' or an instance of 'int'. Got 'True' instead."
     ]
    }
   ],
   "source": [
    "# transform the text data to feature vectors that can be used as input to the Logistic regression\n",
    "\n",
    "feature_extraction = TfidfVectorizer(min_df = 1, stop_words='english', lowercase='True')\n",
    "\n",
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test)\n",
    "\n",
    "# convert Y_train and Y_test values as integers\n",
    "\n",
    "Y_train = Y_train.astype('int')\n",
    "Y_test = Y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dBMAcw9RUkUY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3075                  Don know. I did't msg him recently.\n",
      "1787    Do you know why god created gap between your f...\n",
      "1614                         Thnx dude. u guys out 2nite?\n",
      "4304                                      Yup i'm free...\n",
      "3266    44 7732584351, Do you want a New Nokia 3510i c...\n",
      "                              ...                        \n",
      "789     5 Free Top Polyphonic Tones call 087018728737,...\n",
      "968     What do u want when i come back?.a beautiful n...\n",
      "1667    Guess who spent all last night phasing in and ...\n",
      "3321    Eh sorry leh... I din c ur msg. Not sad alread...\n",
      "1688    Free Top ringtone -sub to weekly ringtone-get ...\n",
      "Name: Message, Length: 4457, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1NFuGogZUpt0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mX_train_features\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_features' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q86FvELbU_SV"
   },
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hV6BAIZQVBbo"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1JeAOwzpUv0V"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWGRHWAPVI_z",
    "outputId": "1c5e15dd-0e07-4871-c4fa-b908ee400b55"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# training the Logistic Regression model with the training data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train_features\u001b[49m, Y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_features' is not defined"
     ]
    }
   ],
   "source": [
    "# training the Logistic Regression model with the training data\n",
    "model.fit(X_train_features, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ01fa8dVeL5"
   },
   "source": [
    "Evaluating the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ExiF2kKxVYtC"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# prediction on training data\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m prediction_on_training_data \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_train_features\u001b[49m)\n\u001b[0;32m      4\u001b[0m accuracy_on_training_data \u001b[38;5;241m=\u001b[39m accuracy_score(Y_train, prediction_on_training_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_features' is not defined"
     ]
    }
   ],
   "source": [
    "# prediction on training data\n",
    "\n",
    "prediction_on_training_data = model.predict(X_train_features)\n",
    "accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7t4DI5UWCkB",
    "outputId": "49fafbb0-0e7f-40c7-9ab7-4aea165731ee"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_on_training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy on training data : \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43maccuracy_on_training_data\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_on_training_data' is not defined"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training data : ', accuracy_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "cTin5rXTWKg3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# prediction on test data\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m prediction_on_test_data \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_test_features\u001b[49m)\n\u001b[0;32m      4\u001b[0m accuracy_on_test_data \u001b[38;5;241m=\u001b[39m accuracy_score(Y_test, prediction_on_test_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_features' is not defined"
     ]
    }
   ],
   "source": [
    "# prediction on test data\n",
    "\n",
    "prediction_on_test_data = model.predict(X_test_features)\n",
    "accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gvoMK4OWnJY",
    "outputId": "7bf56da4-1987-4828-ea00-95c30fb083d1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_on_test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy on test data : \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43maccuracy_on_test_data\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_on_test_data' is not defined"
     ]
    }
   ],
   "source": [
    "print('Accuracy on test data : ', accuracy_on_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXdOKxYAXaHC"
   },
   "source": [
    "Building a Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h60z1__mWql6",
    "outputId": "3aac53f3-13f2-4afb-e9f2-75d337cbcd44"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_extraction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m input_mail \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# convert text to feature vectors\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m input_data_features \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extraction\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(input_mail)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# making prediction\u001b[39;00m\n\u001b[0;32m      8\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(input_data_features)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_extraction' is not defined"
     ]
    }
   ],
   "source": [
    "input_mail = [\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times\"]\n",
    "\n",
    "# convert text to feature vectors\n",
    "input_data_features = feature_extraction.transform(input_mail)\n",
    "\n",
    "# making prediction\n",
    "\n",
    "prediction = model.predict(input_data_features)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "if (prediction[0]==1):\n",
    "  print('Ham mail')\n",
    "\n",
    "else:\n",
    "  print('Spam mail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v_LqbM_ZYwS1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5572, 2)\n",
      "Columns: ['Category', 'Message']\n",
      "  Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "\n",
      "üìä Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9865    0.9824    0.9844       966\n",
      "           1     0.8889    0.9128    0.9007       149\n",
      "\n",
      "    accuracy                         0.9731      1115\n",
      "   macro avg     0.9377    0.9476    0.9426      1115\n",
      "weighted avg     0.9734    0.9731    0.9732      1115\n",
      "\n",
      "\n",
      "‚úÖ Accuracy: 0.9730941704035875\n",
      "\n",
      "Confusion Matrix:\n",
      " [[949  17]\n",
      " [ 13 136]]\n",
      "\n",
      "‚úÖ Model and Vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# üìò Phishing / Spam Mail Detection using Machine Learning\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------\n",
    "# 1Ô∏è‚É£ Load the dataset\n",
    "# -----------------------\n",
    "data = pd.read_csv('mail_data.csv')\n",
    "\n",
    "# Check structure\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"Columns:\", data.columns.tolist())\n",
    "print(data.head())\n",
    "\n",
    "# If dataset has unnamed index column, drop it\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# -----------------------\n",
    "# 2Ô∏è‚É£ Clean and preprocess\n",
    "# -----------------------\n",
    "\n",
    "# Rename columns if needed\n",
    "if 'Message' not in data.columns and 'message' in data.columns:\n",
    "    data.rename(columns={'message': 'Message'}, inplace=True)\n",
    "if 'Category' not in data.columns and 'label' in data.columns:\n",
    "    data.rename(columns={'label': 'Category'}, inplace=True)\n",
    "\n",
    "# Remove missing values\n",
    "data = data.dropna(subset=['Message', 'Category'])\n",
    "\n",
    "# Convert labels to binary\n",
    "data['Category'] = data['Category'].map({'spam': 1, 'ham': 0, 'phishing': 1}).fillna(0).astype(int)\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "data['clean_text'] = data['Message'].apply(clean_text)\n",
    "\n",
    "# -----------------------\n",
    "# 3Ô∏è‚É£ Split dataset\n",
    "# -----------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['clean_text'], data['Category'], \n",
    "    test_size=0.2, random_state=42, stratify=data['Category']\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 4Ô∏è‚É£ TF-IDF + Model\n",
    "# -----------------------\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=2000, class_weight='balanced', solver='saga')\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# -----------------------\n",
    "# 5Ô∏è‚É£ Evaluation\n",
    "# -----------------------\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"\\n‚úÖ Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# -----------------------\n",
    "# 6Ô∏è‚É£ Save model & vectorizer\n",
    "# -----------------------\n",
    "import joblib\n",
    "joblib.dump(model, 'phishing_email_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "print(\"\\n‚úÖ Model and Vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in c:\\users\\nithe\\anaconda3\\lib\\site-packages (0.119.0)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\nithe\\anaconda3\\lib\\site-packages (0.37.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\nithe\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nithe\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from fastapi) (2.12.2)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from fastapi) (0.48.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from fastapi) (4.15.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from uvicorn) (8.0.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastapi uvicorn joblib scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter-server in c:\\users\\nithe\\anaconda3\\lib\\site-packages (1.23.4)\n",
      "Collecting jupyter-server\n",
      "  Using cached jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
      "Collecting jupyter-events>=0.11.0\n",
      "  Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (2.0.10)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (0.14.1)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (22.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (4.11.0)\n",
      "Requirement already satisfied: traitlets>=5.6.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (5.7.1)\n",
      "Collecting jupyter-client>=7.4.4\n",
      "  Using cached jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (5.7.0)\n",
      "Collecting pyzmq>=24\n",
      "  Using cached pyzmq-27.1.0-cp310-cp310-win_amd64.whl (632 kB)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (6.5.2)\n",
      "Collecting jupyter-server-terminals>=0.4.4\n",
      "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (5.2.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (0.17.1)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (6.5.4)\n",
      "Collecting overrides>=5.0\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (21.3.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (3.1.2)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-server) (1.9.0)\n",
      "Collecting send2trash>=1.8.2\n",
      "  Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server) (1.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server) (4.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server) (21.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-client>=7.4.4->jupyter-server) (2.8.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server) (305.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server) (2.5.2)\n",
      "Collecting jsonschema[format-nongpl]>=4.18.0\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server) (6.0)\n",
      "Collecting python-json-logger>=2.0.4\n",
      "  Using cached python_json_logger-4.0.0-py3-none-any.whl (15 kB)\n",
      "Collecting rfc3339-validator\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Collecting referencing\n",
      "  Using cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Collecting rfc3986-validator>=0.1.1\n",
      "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server) (0.8.4)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server) (2.11.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server) (0.5.13)\n",
      "Requirement already satisfied: lxml in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server) (4.9.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server) (1.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server) (4.11.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server) (0.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server) (4.1.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server) (0.1.2)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server) (4.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.3.0->jupyter-server) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.3.0->jupyter-server) (0.18.0)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Using cached rpds_py-0.27.1-cp310-cp310-win_amd64.whl (228 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server) (24.11.1)\n",
      "Collecting fqdn\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting jsonpointer>1.13\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: uri-template in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server) (1.3.0)\n",
      "Collecting rfc3987-syntax>=1.1.0\n",
      "  Using cached rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "Collecting isoduration\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from nbclient>=0.5.0->nbconvert>=6.4.4->jupyter-server) (1.5.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from bleach->nbconvert>=6.4.4->jupyter-server) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server) (2.21)\n",
      "Collecting lark>=1.2.2\n",
      "  Using cached lark-1.3.0-py3-none-any.whl (113 kB)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\nithe\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server) (1.2.3)\n",
      "Installing collected packages: send2trash, rpds-py, rfc3986-validator, rfc3339-validator, pyzmq, python-json-logger, overrides, lark, jsonpointer, fqdn, attrs, rfc3987-syntax, referencing, jupyter-server-terminals, jupyter-client, jsonschema-specifications, isoduration, jsonschema, jupyter-events, jupyter-server\n",
      "  Attempting uninstall: send2trash\n",
      "    Found existing installation: Send2Trash 1.8.0\n",
      "    Uninstalling Send2Trash-1.8.0:\n",
      "      Successfully uninstalled Send2Trash-1.8.0\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 23.2.0\n",
      "    Uninstalling pyzmq-23.2.0:\n",
      "      Successfully uninstalled pyzmq-23.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\nithe\\\\anaconda3\\\\Lib\\\\site-packages\\\\~mq\\\\backend\\\\cython\\\\context.cp310-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install -U jupyter-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
